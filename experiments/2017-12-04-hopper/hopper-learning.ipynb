{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RigidBodyDynamics\n",
    "using DrakeVisualizer\n",
    "DrakeVisualizer.any_open_windows() || DrakeVisualizer.new_window()\n",
    "using RigidBodyTreeInspector\n",
    "using Gurobi\n",
    "import StochasticOptimization\n",
    "using Plots; gr()\n",
    "using JLD2\n",
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LCPSim\n",
    "import LearningMPC\n",
    "import Hoppers\n",
    "import Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Hoppers.Hopper()\n",
    "mechanism = robot.mechanism\n",
    "xstar = Hoppers.nominal_state(robot)\n",
    "\n",
    "basevis = Visualizer()[:hopper]\n",
    "setgeometry!(basevis, robot)\n",
    "settransform!(basevis[:robot], xstar)\n",
    "\n",
    "mpc_params = LearningMPC.MPCParams(\n",
    "    Δt=0.05,\n",
    "    horizon=10,\n",
    "    mip_solver=GurobiSolver(Gurobi.Env(), OutputFlag=0, TimeLimit=120, MIPGap=1e-1, FeasibilityTol=1e-3),\n",
    "    lcp_solver=GurobiSolver(Gurobi.Env(), OutputFlag=0))\n",
    "\n",
    "Q, R = Hoppers.default_costs(robot)\n",
    "foot = findbody(mechanism, \"foot\")\n",
    "lqrsol = LearningMPC.LQRSolution(xstar, Q, R, mpc_params.Δt, [Point3D(default_frame(foot), 0., 0., 0.)])\n",
    "lqrsol.S .= 1 ./ mpc_params.Δt .* Q\n",
    "\n",
    "hidden_widths = [16, 8, 8, 8]\n",
    "activation = Nets.leaky_relu\n",
    "net = LearningMPC.control_net(mechanism, hidden_widths, activation)\n",
    "\n",
    "net_controller = x -> Nets.predict(net, state_vector(x))\n",
    "\n",
    "mpc_controller = LearningMPC.MPCController(mechanism, \n",
    "    robot.environment, mpc_params, lqrsol, \n",
    "    [net_controller, lqrsol]);\n",
    "\n",
    "sample_sink = LearningMPC.MPCSampleSink{Float64}()\n",
    "playback_sink = LearningMPC.PlaybackSink(basevis[:robot], 0.25 * mpc_params.Δt)\n",
    "live_viewer = LearningMPC.live_viewer(mechanism, basevis[:robot])\n",
    "\n",
    "mpc_controller.callback = LearningMPC.call_each(\n",
    "    sample_sink,\n",
    "#     playback_sink,\n",
    "#     (args...) -> println(\"tick\")\n",
    "#     (x, results) -> live_viewer(x)\n",
    ")\n",
    "\n",
    "\n",
    "dagger_controller = LearningMPC.call_each(\n",
    "    LearningMPC.dagger_controller(\n",
    "        mpc_controller,\n",
    "        net_controller,\n",
    "        0.5),\n",
    "    live_viewer\n",
    "    )\n",
    "\n",
    "termination = x -> false\n",
    "\n",
    "dataset = LearningMPC.Dataset(lqrsol)\n",
    "\n",
    "# updater = Nets.adam_updater(net)\n",
    "# gradient_sensitivity = 0.2\n",
    "# loss = LearningMPC.sensitive_loss(net, gradient_sensitivity)\n",
    "# adam_opts = Nets.AdamOpts(learning_rate=1e-2, batch_size=1)\n",
    "\n",
    "gradient_sensitivity = 0.2\n",
    "learning_loss = LearningMPC.sensitive_loss(net, gradient_sensitivity)\n",
    "adam_opts = Nets.AdamOpts(learning_rate=2e-2, batch_size=1)\n",
    "optimizer = Nets.AdamOptimizer(learning_loss, adam_opts, net, \n",
    "    zeros(length(net.input_tform.v)), zeros(length(net.output_tform.v), 1 + length(net.input_tform.v)))\n",
    "\n",
    "\n",
    "x0 = MechanismState{Float64}(mechanism)\n",
    "\n",
    "x_init = MechanismState{Float64}(mechanism)\n",
    "set_configuration!(x_init, [1.0, 1.0])\n",
    "set_velocity!(x_init, [0., 0.])\n",
    "# x_init = xstar\n",
    "\n",
    "function collect_into!(data::Vector{<:LearningMPC.Sample})\n",
    "    empty!(sample_sink)\n",
    "    LearningMPC.randomize!(x0, x_init, 0.5, 1.0)\n",
    "    if configuration(x0)[1] - configuration(x0)[2] < 0\n",
    "        set_configuration!(x0, [configuration(x0)[2], configuration(x0)[2]])\n",
    "    end\n",
    "    results = LCPSim.simulate(x0, \n",
    "        dagger_controller,\n",
    "        robot.environment, mpc_params.Δt, 50, \n",
    "        mpc_params.lcp_solver;\n",
    "        termination=termination);\n",
    "    samples_to_keep = filter(1:length(sample_sink.samples)) do i\n",
    "        for j in (i+1):length(sample_sink.samples)\n",
    "            if norm(sample_sink.samples[j].state .- sample_sink.samples[i].state) < 1e-2\n",
    "                return false\n",
    "            end\n",
    "        end\n",
    "        return true\n",
    "    end\n",
    "    append!(data, sample_sink.samples[samples_to_keep])\n",
    "#     append!(data, sample_sink.samples)\n",
    "end\n",
    "\n",
    "all_losses(net, dataset) = (LearningMPC.training_loss(net, dataset),\n",
    "                            LearningMPC.validation_loss(net, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(net.params.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LearningMPC.randomize!(x0, x_init, 0.0, 0.0)\n",
    "# results = LCPSim.simulate(x0, \n",
    "#     mpc_controller,\n",
    "#     robot.environment, mpc_params.Δt, 50, mpc_params.lcp_solver);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LearningMPC.playback(basevis[:robot], results, mpc_params.Δt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "losses = Tuple{Float64, Float64}[]\n",
    "snapshots = LearningMPC.Snapshot{Float64}[]\n",
    "gr()\n",
    "\n",
    "@showprogress for i in 1:10\n",
    "    for i in 1:2\n",
    "        collect_into!(dataset.training_data)\n",
    "    end\n",
    "    collect_into!(dataset.testing_data)\n",
    "    collect_into!(dataset.validation_data);\n",
    "    \n",
    "    @showprogress for i in 1:10\n",
    "        Nets.update!(net.params.data, optimizer, LearningMPC.features.(dataset.training_data))\n",
    "        optimizer.opts.learning_rate *= (1 - 3e-2)\n",
    "#             Nets.adam_update!(net.params.data, updater, loss, \n",
    "#                 LearningMPC.features.(dataset.training_data), adam_opts);\n",
    "        push!(losses, all_losses(net, dataset))\n",
    "    end\n",
    "    \n",
    "    push!(snapshots, LearningMPC.Snapshot(net.params.data, net))\n",
    "    \n",
    "    jldopen(\"hopper-$gradient_sensitivity.jld2\", \"w\") do file\n",
    "        file[\"dataset\"] = dataset\n",
    "        file[\"snapshots\"] = snapshots\n",
    "    end\n",
    "    \n",
    "    plt = plot(first.(losses), label=\"training\", yscale=:log10)\n",
    "    plot!(plt, last.(losses), label=\"validation\")\n",
    "    ylims!(plt, (1, ylims(plt)[2]))\n",
    "    display(plt)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @showprogress for i in 1:100\n",
    "#     Nets.update!(net.params.data, optimizer, LearningMPC.features.(dataset.training_data))\n",
    "#     optimizer.opts.learning_rate *= (1 - 3e-2)\n",
    "#     push!(losses, all_losses(net, dataset))\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plot(first.(losses), label=\"training\", yscale=:log10)\n",
    "plot!(plt, last.(losses), label=\"validation\")\n",
    "ylims!(plt, (1, ylims(plt)[2]))\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LearningMPC.randomize!(x0, x_init, 0.1, 0.5)\n",
    "results = LCPSim.simulate(x0, \n",
    "    net_controller,\n",
    "    robot.environment, mpc_params.Δt, 200, mpc_params.lcp_solver);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LearningMPC.playback(basevis[:robot], results, mpc_params.Δt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function slice(data)\n",
    "    filter(data) do sample\n",
    "        x = sample.state\n",
    "        (abs(x[1] - x[2]) < 1e-1) && (abs(x[3] - x[4]) < 1e-1)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plot([s.state[1] for s in slice(dataset.training_data)], [s.state[3] for s in slice(dataset.training_data)],\n",
    "     [s.uJ[2, 1] for s in slice(dataset.training_data)], line=nothing, marker=:dot, markersize=0.3)\n",
    "surface!(plt, linspace(0, 2), linspace(-4, 4), (x, y) -> net([x, x, y, y])[2])\n",
    "# plot!(plt, [s.state[1] for s in dataset.training_data], [s.state[3] for s in dataset.training_data],\n",
    "#      [net(s.state)[2] for s in dataset.training_data], line=nothing, marker=:dot, markersize=0.3, markercolor=:red)\n",
    "zlims!(plt, -10, 50)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
