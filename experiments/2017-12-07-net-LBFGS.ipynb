{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim\n",
    "using ForwardDiff\n",
    "using Plots; gr()\n",
    "using ColorTypes\n",
    "using ReverseDiff\n",
    "using Base.Test\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Nets\n",
    "import LearningMPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = x -> [sin(x[1])]\n",
    "# target = x -> x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pts = linspace(-2π, 0, 5)\n",
    "sample(x) = ([x], hcat(target(x), ForwardDiff.jacobian(target, [x])))\n",
    "training_data = [sample(x) for x in training_pts];\n",
    "# training_data = Tuple{Vector{Float64}, Matrix{Float64}}[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Nets.Net(zeros(Nets.Params{Float64}, [1, 10, 10, 1]), Nets.elu)\n",
    "for I in eachindex(net.params.data)\n",
    "    net.params.data[I] += 0.1 * randn()\n",
    "end\n",
    "\n",
    "f, g! = Nets.cost_function(net, training_data, 0.5)\n",
    "@inferred f(net.params.data)\n",
    "@inferred g!(similar(net.params.data), net.params.data)\n",
    "@inferred Nets.predict_sensitivity(net, zeros(1))\n",
    "∇ = similar(net.params.data);\n",
    "# @benchmark $g!($∇, $(net.params.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@show f(net.params.data)\n",
    "solver = LBFGS()\n",
    "options = Optim.Options()\n",
    "@time results = optimize(f, g!, copy(net.params.data), solver, options)\n",
    "net.params.data .= results.minimizer;\n",
    "@show f(net.params.data)\n",
    "\n",
    "for i in 1:10\n",
    "    push!(training_data, sample(randn() + 0.5))\n",
    "end\n",
    "@show f(net.params.data)\n",
    "\n",
    "@time results = optimize(f, g!, copy(net.params.data), solver, options)\n",
    "net.params.data .= results.minimizer;\n",
    "@show f(net.params.data)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plot([x[1] for (x, yJ) in training_data], \n",
    "    [yJ[1] for (x, yJ) in training_data],\n",
    "    line=nothing,\n",
    "    marker=:dot)\n",
    "for (x, yJ) in training_data\n",
    "    y = yJ[1, 1]\n",
    "    slope = yJ[1, 2]\n",
    "    θ = atan(slope)\n",
    "    δx = 0.1 * cos(θ)\n",
    "    xs = [x[1] - δx, x[1] + δx]\n",
    "    ys = [y - slope * δx, y + slope * δx]\n",
    "    plot!(plt, xs, ys, color=colorant\"red\", legend=nothing)\n",
    "end\n",
    "\n",
    "x_samples = linspace(-2π, 2π, 101)\n",
    "plot!(plt, x_samples, [net([x])[1] for x in x_samples], color=colorant\"blue\")\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
